---
title: "Western Virginia Water Authority"
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r setup}
library(ggiraph)
library(patchwork)
library(tidyverse)
library(neon4cast)
library(score4cast)


library(thematic)
thematic_rmd(bg="white", fg="black", accent="blue")

source("R/flare-plots.R")
source("R/ignore_sigpipes.R")


```

```{r include=FALSE}

```

## Most recent forecasts

Below are forecasts for three reservoirs managed by the Western Virginia Water Authority (WVWA). The WVWA is the primary supplier of drinking water to the Roanoke, VA region.  

Forecasts are developed in [partnership with WVWA](https://video.vt.edu/media/Researchers%20craft%20unique%20system%20for%20predicting%20water%20quality%20in%20reservoir/1_9ok8r6ty).  More information about past performance at Falling Creek Reservoir can be found in [Thomas et al. 2020](https://doi.org/10.1029/2019WR026138)

::: panel-tabset
## Falling Creek Reservoir

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("fcre")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("fcre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r fcre-temp}
df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "fcre")

plot_temp(df_insitu_scores_lake, depths = c(1,8)) 
```

```{r fcre-depth, eval=F}
# depth plot
depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("fcre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

plot_depth(depth_scores) 
```

```{r fcre-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = FALSE) |> 
  filter(variable == "temperature",
         site_id %in% c("fcre"),
         reference_datetime == most_recent) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = c(1, 8), use_density = T, threshold = 0.1)

```

```{r fcre-ice}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("fcre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

plot_ice(ice_forecasts)
```

```{r eval = FALSE}

#Past Performance
df <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         depth %in% c(1.0),
         site_id == "fcre") |> 
  dplyr::collect() 

bounds <- range(c(df$observation, df$mean), na.rm = TRUE)
  
  df |> 
  filter(horizon > 0) |> 
  ggplot(aes(x = observation, y = mean, color = factor(horizon))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  ylim(bounds) +
  xlim(bounds) +
  labs(x = "observed", y = "predicted") +
  theme_bw()

```

```{r eval = FALSE}
#Compare forecasts
s3_score <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

full_forecast <- arrow::open_dataset(s3_score) |> 
  filter(site_id == "fcre") |> 
  distinct(reference_datetime) |> 
  collect() |> 
  filter(lubridate::as_date(reference_datetime) >= Sys.Date() - lubridate::days(16)) |> 
  summarize(min = min(reference_datetime)) |> 
  pull(min)

df_insitu_forecast <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         depth == 1.0,
         reference_datetime == full_forecast,
         site_id == "fcre") |> 
  select(site_id, reference_datetime, datetime, family, parameter, variable, prediction) |> 
  dplyr::collect()  |> 
  mutate(reference_datetime = lubridate::as_datetime(reference_datetime),
         datetime = lubridate::as_datetime(datetime))
  

noaa_date <- as.character(lubridate::as_date(df_insitu_forecast$reference_datetime)[1])
s3_score <- arrow::s3_bucket(bucket = "drivers/noaa/gefs-v12/stage2/parquet/0", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
noaa_df <- arrow::open_dataset(s3_score, partitioning = "reference_date") |> 
  filter(variable == "air_temperature",
         reference_date == noaa_date,
         horizon <= 16 * 24, 
         site_id %in% c("fcre")) |> 
  select(site_id, reference_datetime, datetime, family, parameter, variable, prediction) |> 
  dplyr::collect() |> 
  mutate(prediction = prediction - 273.15)

  

s3_score <- arrow::s3_bucket(bucket = "drivers/inflow/fcre_v2/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
inflow_df <- arrow::open_dataset(s3_score, partitioning = c("model_id","site_id","cycle","reference_date")) |> 
  filter(reference_date == noaa_date,
         cycle == 0,
         flow_type == "inflow",
         variable %in% c("TEMP")) |> 
  select(site_id, reference_datetime, datetime, family, parameter, variable, prediction) |> 
  collect() |> 
  mutate(reference_datetime = lubridate::as_datetime(reference_datetime),
         datetime = lubridate::as_datetime(datetime),
         variable = ifelse(variable == "TEMP","inflow_temperature",variable))

combined <- bind_rows(df_insitu_forecast, noaa_df, inflow_df)
```

```{r eval = FALSE}
insitu_target_file <- "https://s3.flare-forecast.org/targets/fcre_v2/fcre/fcre-targets-insitu.csv"
met_targets_file <- "https://s3.flare-forecast.org/targets/fcre_v2/fcre/observed-met_fcre.csv"
inflow_targets_file <- "https://s3.flare-forecast.org/targets/fcre_v2/fcre/fcre-targets-inflow.csv"

insitu_target <- readr::read_csv(insitu_target_file, show_col_types = FALSE) |>
  filter(depth == 1.0) |> 
  #dplyr::mutate(site_id = paste0(site_id,"-",depth)) |> 
  select(-depth)

met_targets <- readr::read_csv(met_targets_file, show_col_types = FALSE) |> 
  filter(variable == "air_temperature") |> 
  mutate(observation = observation - 273.15)


inflow_targets <- readr::read_csv(inflow_targets_file, show_col_types = FALSE) |> 
  filter(variable == "TEMP") |> 
  mutate(variable = ifelse(variable == "TEMP", "inflow_temperature", variable)) |> 
  mutate(datetime = lubridate::as_datetime(datetime))

target <- bind_rows(insitu_target, met_targets, inflow_targets)

df2 <- combined %>%
  score4cast::standardize_forecast() %>%
  mutate(family = as.character(family)) |> 
  score4cast::crps_logs_score(target) %>%
  mutate(horizon = datetime-lubridate::as_datetime(reference_datetime)) %>%
  mutate(horizon = as.numeric(lubridate::as.duration(horizon),
                              units = "seconds"),
         horizon = horizon / 86400)  |> 
  mutate(variable = ifelse(variable == "temperature", "lake_temperature", variable))
```

```{r eval = FALSE}
#Analyze weather, inflow, and lake forecasts
df2 |> 
  dplyr::filter(horizon > 0) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  #geom_line(aes(y = mean)) +
  geom_point(aes(y = observation)) +
  facet_wrap(~variable, scale = "free") +
  labs(y = "value") +
  theme_bw()

```

## Beaver Dam Reservoir

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("bvre")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("bvre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "bvre")

plot_temp(df_insitu_scores_lake, depths = c(1,8))  
```

```{r bvre-depth, eval=F}
# depth plot
depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("bvre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

plot_depth(depth_scores) 
```

```{r bvre-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "temperature",
         site_id %in% c("bvre"),
         reference_datetime == most_recent) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = c(1, 9), use_density = T, threshold = 0.1)

```

```{r bvre-ice}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("bvre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

plot_ice(ice_forecasts)
```

```{r eval = FALSE}
df <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(1.0),
         site_id == "bvre") |> 
  dplyr::collect() 

bounds <- range(c(df$observation, df$mean), na.rm = TRUE)
  
  df |> 
  filter(horizon > 0) |> 
  ggplot(aes(x = observation, y = mean, color = factor(horizon))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  ylim(bounds) +
  xlim(bounds) +
  labs(x = "observed", y = "predicted") +
  theme_bw()
```

## Carvins Cove Reservoir

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("ccre")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("ccre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "ccre")

plot_temp(df_insitu_scores_lake, depths = c(1,8))  
```

```{r ccre-depth, eval=F}
# depth plot
depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("ccre"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

plot_depth(depth_scores) 
```

```{r ccre-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "temperature",
         site_id %in% c("ccre"),
         reference_datetime == most_recent) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = c(1, 19), use_density = T, threshold = 0.1)

```

```{r ccre-ice}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("ccre"),
         reference_datetime == most_recent,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_ice(ice_forecasts)
```

```{r eval = FALSE}
df <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(1.0),
         site_id == "ccre") |> 
  dplyr::collect() 

bounds <- range(c(df$observation, df$mean), na.rm = TRUE)
  
  df |> 
  filter(horizon > 0) |> 
  ggplot(aes(x = observation, y = mean, color = factor(horizon))) +
  geom_point() +
  geom_abline(slope = 1, intercept = 0) +
  ylim(bounds) +
  xlim(bounds) +
  labs(x = "observed", y = "predicted") +
  theme_bw()
```
:::
