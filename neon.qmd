---
title: "National Ecological Observatory Network"
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r setup}
library(ggiraph)
library(patchwork)
library(tidyverse)
library(neon4cast)
library(score4cast)


library(thematic)
thematic_rmd(bg="white", fg="black", accent="blue")

#source("R/plot-utils.R")


```

## Most recent forecasts

The National Ecological Observatory Network (NEON) is a U.S. National Science Foundation funded project to monitor 81 ecosystems across the U.S. using standardized measurements over the next 30 years. We generate forecast for the seven lakes that are monitored by NEON. These lakes range from hot humid (Florida) to cold tundra (Alaska) environments.

::: panel-tabset
## Barco Lake

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("BARC")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("BARC"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "BARC")
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20))  

```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("BARC"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  
```

## Crampton Lake

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("CRAM")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("CRAM"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "CRAM") 
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20))  
```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("CRAM"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  

```

```{r}
# Ice plot
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("CRAM"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

# Calculate the % chance of ice yes/no
ice_forecasts %>%
  mutate(ice = ifelse(prediction > 0, 1, 0)) %>% 
  dplyr::filter(datetime >= reference_datetime) |> 
  group_by(datetime) %>% 
  summarise(percent_ice = 100*(sum(ice)/n())) %>%
  ggplot(., aes(datetime, y=percent_ice)) +
  geom_line() +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(0,100)) +
  labs(y = '% chance of ice') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20), 
        plot.caption = element_text(size = 12),
        panel.grid.minor = element_blank())
 
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```

## Little Rock Lake

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("LIRO")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("LIRO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "LIRO")
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20))  

```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("LIRO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  

```

```{r eval = TRUE}
# Ice plot
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("LIRO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

# Calculate the % chance of ice yes/no
ice_forecasts %>%
  mutate(ice = ifelse(prediction > 0, 1, 0)) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  group_by(datetime) %>% 
  summarise(percent_ice = 100*(sum(ice)/n())) %>%
  ggplot(., aes(datetime, y=percent_ice)) +
  geom_line() +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(0,100)) +
  labs(y = '% chance of ice') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20), 
        plot.caption = element_text(size = 12),
        panel.grid.minor = element_blank())

#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon. 
```



## Prairie Lake

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("PRLA")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("PRLA"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "PRLA")
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20)) 

```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  

```

```{r eval = TRUE}
# Ice plot
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

# Calculate the % chance of ice yes/no
ice_forecasts %>%
  mutate(ice = ifelse(prediction > 0, 1, 0)) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  group_by(datetime) %>% 
  summarise(percent_ice = 100*(sum(ice)/n())) %>%
  ggplot(., aes(datetime, y=percent_ice)) +
  geom_line() +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(0,100)) +
  labs(y = '% chance of ice') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20), 
        plot.caption = element_text(size = 12),
        panel.grid.minor = element_blank())
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```



## Prairie Pothole

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("PRPO")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("PRPO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "PRPO")
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20))  

```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("PRPO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  

```

```{r prpo-ice, eval = TRUE}
# Ice plot
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("PRPO"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

# Calculate the % chance of ice yes/no
ice_forecasts %>%
  mutate(ice = ifelse(prediction > 0, 1, 0)) %>%  
  dplyr::filter(datetime >= reference_datetime) %>% 
  group_by(datetime) %>% 
  summarise(percent_ice = 100*(sum(ice)/n())) %>%
  ggplot(., aes(datetime, y=percent_ice)) +
  geom_line() +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(0,100)) +
  labs(y = '% chance of ice') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20), 
        plot.caption = element_text(size = 12),
        panel.grid.minor = element_blank())
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```


## Suggs Lake

```{r}
s3 <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)

most_recent <-  arrow::open_dataset(s3) |> 
  filter(site_id %in% c("SUGG")) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "temperature",
         depth %in% c(0.5),
         site_id %in% c("SUGG"),
         reference_datetime == most_recent) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r}
## date of each team's most recent forecast
df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "SUGG")
my_breaks <- lubridate::with_tz(seq(min(df_insitu_scores_lake$datetime), max(df_insitu_scores_lake$datetime), by = "1 day"),"America/New_York")   
my_label <- seq(lubridate::as_datetime(df_insitu_scores_lake$reference_datetime)[1], max(df_insitu_scores_lake$datetime), by = "5 days")
my_labels <- as.character(my_breaks)
my_labels[which(!(my_breaks %in% my_label))] <- " "

y_label <- expression(paste('Water temperature (',degree,'C)', sep = ""))
df_insitu_scores_lake |> 
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York"),
                depth = paste0("Depth: ", depth)) |> 
  dplyr::filter(datetime >= reference_datetime) |> 
  ggplot(aes(x = datetime)) +
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), fill = "lightblue", color = "lightblue") +
  geom_line(aes(y = mean)) +
  #geom_point(aes(y = observation)) +
  #geom_vline(aes(xintercept = reference_datetime)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  facet_wrap(~depth) +
  labs(y = y_label) +
  ylim(c(-5,35)) +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20))
```

```{r}
# depth plot

depth_scores <- arrow::open_dataset(s3) |> 
  filter(variable == "depth",
         site_id %in% c("SUGG"),
         reference_datetime == most_recent) |> 
  dplyr::collect()

depth_change <- ceiling((max(depth_scores$mean) - min(depth_scores$mean))*2)/2
max_depth <- ceiling(max(depth_scores$mean)*2)/2

depth_scores %>%
  dplyr::mutate(datetime = lubridate::with_tz(lubridate::as_datetime(datetime), "America/New_York"),
                reference_datetime = lubridate::with_tz(lubridate::as_datetime(reference_datetime), "America/New_York")) %>% 
  dplyr::filter(datetime >= reference_datetime) %>% 
  ggplot(., aes(x=datetime))+
  geom_ribbon(aes(ymin = quantile10, ymax = quantile90), colour = 'lightgreen', fill = 'lightgreen') +
  geom_line(aes( y=mean)) +
  scale_x_continuous(breaks = my_breaks, labels = my_labels) +
  scale_y_continuous(limits = c(max_depth - depth_change, max_depth)) +
  labs(y = 'Lake depth (m)') +
  theme_bw() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=0.2)) +
  theme(text = element_text(size = 20),
        panel.grid.minor = element_blank())  


```
:::
