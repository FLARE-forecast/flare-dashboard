---
title: "National Ecological Observatory Network"
---

```{r, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message=FALSE, warning=FALSE)
```

```{r setup}
library(ggiraph)
library(patchwork)
library(tidyverse)
library(neon4cast)
library(score4cast)


library(thematic)
thematic_rmd(bg="white", fg="black", accent="blue")

source("R/flare-plots.R")
source("R/ignore_sigpipes.R")

forecast_flare_model <- 'test_runS3'
```

## Most recent forecasts

The National Ecological Observatory Network (NEON) is a U.S. National Science Foundation funded project to monitor 81 ecosystems across the U.S. using standardized measurements over the next 30 years. We generate forecast for the seven lakes that are monitored by NEON. These lakes range from hot humid (Florida) to cold tundra (Alaska) environments.

::: panel-tabset
## Barco Lake

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("BARC"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("BARC"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r barc-temp}
df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "BARC")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r barc-depth, eval=F}
# depth plot
depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("BARC"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_depth(depth_scores) 
```

```{r barc-mixing}

most_recent <-  arrow::open_dataset(s3_forecast) |> 
  filter(site_id %in% c("BARC"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()


# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "temperature",
         site_id %in% c("BARC"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect()

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

## Crampton Lake

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("CRAM"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("CRAM"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r cram-temp}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "CRAM")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))
```

```{r cram-depth, eval = F}
# depth plot

depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("CRAM"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_depth(depth_scores)

```

```{r cram-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "temperature",
         site_id %in% c("CRAM"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect()

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

```{r cram-ice}
# Ice plot
#ice_forecasts <- arrow::open_dataset(s3_forecast) |> 
#  filter(variable == "ice_thickness",
#         site_id %in% c("CRAM"),
#         reference_datetime == most_recent) |> 
#  dplyr::collect()

#plot_ice(ice_forecasts)
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```

## Little Rock Lake

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("LIRO"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("LIRO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r liro-temp}

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "LIRO")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r liro-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "temperature",
         site_id %in% c("LIRO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

```{r liro-depth, eval= F}
# depth plot

depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("LIRO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_depth(depth_scores)

```

```{r liro-ice, eval = TRUE}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("LIRO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_ice(ice_forecasts)
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon. 
```

## Prairie Lake

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("PRLA"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("PRLA"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r prla-temp}
df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "PRLA")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r prla-depth, eval = F}
# depth plot

depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_depth(depth_scores) 

```

```{r prla-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "temperature",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

```{r prla-ice, eval = TRUE}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_ice(ice_forecasts)
#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```

## Prairie Pothole

```{r}
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("PRPO"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("PRPO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r prpo-temp}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "PRPO")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r prpo-depth, eval = F}
# depth plot

depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("PRPO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_depth(depth_scores) 

```

```{r prpo-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "temperature",
         site_id %in% c("PRPO"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

```{r prpo-ice, eval = TRUE}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("PRLA"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_ice(ice_forecasts)

#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```

## Suggs Lake

```{r }
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("SUGG"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("SUGG"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r sugg-temp}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "SUGG")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r sugg-depth, eval = F}
# depth plot
depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("SUGG"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect() 

plot_depth(depth_scores)  


```

```{r sugg-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "temperature",
         site_id %in% c("SUGG"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

## Toolik Lake

```{r }
s3_score <- arrow::s3_bucket(bucket = "scores/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
s3_forecast <- arrow::s3_bucket(bucket = "forecasts/parquet", endpoint_override = "s3.flare-forecast.org", anonymous = TRUE)
  
most_recent <-  arrow::open_dataset(s3_score) |> 
  filter(site_id %in% c("TOOK"),
         model_id == forecast_flare_model) |> 
  summarize(max = max(reference_datetime)) |> 
  collect() |> 
  pull()

df_insitu_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "temperature",
         # depth %in% c(0.5),
         site_id %in% c("TOOK"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()
```

The most recent forecast is from `r lubridate::with_tz(lubridate::as_datetime(most_recent), tzone = "America/New_York")` (Eastern U.S. time).

```{r tool-temp}
## date of each team's most recent forecast

df_insitu_scores_lake <- df_insitu_scores |> 
  filter(site_id == "TOOK")

plot_temp(df_insitu_scores_lake, depths = c('0.5'))

```

```{r tool-depth, eval = F}
# depth plot

depth_scores <- arrow::open_dataset(s3_score) |> 
  filter(variable == "depth",
         site_id %in% c("TOOK"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect() 

plot_depth(depth_scores) 

```

```{r tool-mixing}
# chance of being mixed
temperature_forecast <- arrow::open_dataset(s3_forecast) |> 
  filter(variable == "temperature",
         site_id %in% c("TOOK"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model,
         !is.na(prediction)) |> 
  dplyr::collect() 

plot_mixing(forecast_df = temperature_forecast, eval_depths = 'max/min', use_density = T, threshold = 0.1)

```

```{r took-ice, eval = TRUE}
# Ice plot
ice_forecasts <- arrow::open_dataset(s3_forecast, unify_schemas = TRUE) |> 
  filter(variable == "ice_thickness",
         site_id %in% c("TOOK"),
         reference_datetime == most_recent,
         model_id == forecast_flare_model) |> 
  dplyr::collect()

plot_ice(ice_forecasts)

#Percent chance indicates the proportion of ensemble members that predict ice at each forecast horizon.
```
:::
